{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Limpeza de dados\n",
    "\n",
    "Uma parte muito importante do data wrangling, etapa que limpamos e corrigimos dados no processo de análise, é a limpeza dos dados que não queremos ou estão incompletos\n",
    "\n",
    "Neste episódio vou mostrar desde a identificação de dados incorretos até onde decidimos o que fazer com os mesmos\n",
    "\n",
    "Vamos utilizar basicamente o pandas como Jupyter Notebook\n",
    "\n",
    "Lembrando que fiz um post exclusivamente para identificar dados nulos, veja aqui: https://medium.com/matheusbudkewicz/data-science-tips-01-identificar-dados-faltantes-no-dataset-8ca67fe19c4c\n",
    "\n",
    "Outra observação importante é que estamos utilizando a linguagem Python na lib pandas, mas esta etapa pode ser feito em outras partes do processo, por exemplo em SQL quando obtemos os dados de uma base"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets\n",
    "\n",
    "Vamos utilizar dois conjuntos de dados, para duas aplicações distintas de limpeza\n",
    "\n",
    "O primeiro tem dados de chamadas de emergência, veja aqui:\n",
    "    \n",
    "https://www.kaggle.com/mchirico/montcoalert/version/49#911.csv\n",
    "\n",
    "O segundo é o famosão do Titanic:\n",
    "\n",
    "https://github.com/awesomedata/awesome-public-datasets/tree/master/Datasets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iniciando\n",
    "\n",
    "Vamos importar as libs que usaremos, depois o dataset e testar se está funcionando"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lat</th>\n",
       "      <th>lng</th>\n",
       "      <th>desc</th>\n",
       "      <th>zip</th>\n",
       "      <th>title</th>\n",
       "      <th>timeStamp</th>\n",
       "      <th>twp</th>\n",
       "      <th>addr</th>\n",
       "      <th>e</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40.297876</td>\n",
       "      <td>-75.581294</td>\n",
       "      <td>REINDEER CT &amp; DEAD END;  NEW HANOVER; Station ...</td>\n",
       "      <td>19525.0</td>\n",
       "      <td>EMS: BACK PAINS/INJURY</td>\n",
       "      <td>2015-12-10 17:10:52</td>\n",
       "      <td>NEW HANOVER</td>\n",
       "      <td>REINDEER CT &amp; DEAD END</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>40.258061</td>\n",
       "      <td>-75.264680</td>\n",
       "      <td>BRIAR PATH &amp; WHITEMARSH LN;  HATFIELD TOWNSHIP...</td>\n",
       "      <td>19446.0</td>\n",
       "      <td>EMS: DIABETIC EMERGENCY</td>\n",
       "      <td>2015-12-10 17:29:21</td>\n",
       "      <td>HATFIELD TOWNSHIP</td>\n",
       "      <td>BRIAR PATH &amp; WHITEMARSH LN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>40.121182</td>\n",
       "      <td>-75.351975</td>\n",
       "      <td>HAWS AVE; NORRISTOWN; 2015-12-10 @ 14:39:21-St...</td>\n",
       "      <td>19401.0</td>\n",
       "      <td>Fire: GAS-ODOR/LEAK</td>\n",
       "      <td>2015-12-10 14:39:21</td>\n",
       "      <td>NORRISTOWN</td>\n",
       "      <td>HAWS AVE</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40.116153</td>\n",
       "      <td>-75.343513</td>\n",
       "      <td>AIRY ST &amp; SWEDE ST;  NORRISTOWN; Station 308A;...</td>\n",
       "      <td>19401.0</td>\n",
       "      <td>EMS: CARDIAC EMERGENCY</td>\n",
       "      <td>2015-12-10 16:47:36</td>\n",
       "      <td>NORRISTOWN</td>\n",
       "      <td>AIRY ST &amp; SWEDE ST</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>40.251492</td>\n",
       "      <td>-75.603350</td>\n",
       "      <td>CHERRYWOOD CT &amp; DEAD END;  LOWER POTTSGROVE; S...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EMS: DIZZINESS</td>\n",
       "      <td>2015-12-10 16:56:52</td>\n",
       "      <td>LOWER POTTSGROVE</td>\n",
       "      <td>CHERRYWOOD CT &amp; DEAD END</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         lat        lng                                               desc  \\\n",
       "0  40.297876 -75.581294  REINDEER CT & DEAD END;  NEW HANOVER; Station ...   \n",
       "1  40.258061 -75.264680  BRIAR PATH & WHITEMARSH LN;  HATFIELD TOWNSHIP...   \n",
       "2  40.121182 -75.351975  HAWS AVE; NORRISTOWN; 2015-12-10 @ 14:39:21-St...   \n",
       "3  40.116153 -75.343513  AIRY ST & SWEDE ST;  NORRISTOWN; Station 308A;...   \n",
       "4  40.251492 -75.603350  CHERRYWOOD CT & DEAD END;  LOWER POTTSGROVE; S...   \n",
       "\n",
       "       zip                    title            timeStamp                twp  \\\n",
       "0  19525.0   EMS: BACK PAINS/INJURY  2015-12-10 17:10:52        NEW HANOVER   \n",
       "1  19446.0  EMS: DIABETIC EMERGENCY  2015-12-10 17:29:21  HATFIELD TOWNSHIP   \n",
       "2  19401.0      Fire: GAS-ODOR/LEAK  2015-12-10 14:39:21         NORRISTOWN   \n",
       "3  19401.0   EMS: CARDIAC EMERGENCY  2015-12-10 16:47:36         NORRISTOWN   \n",
       "4      NaN           EMS: DIZZINESS  2015-12-10 16:56:52   LOWER POTTSGROVE   \n",
       "\n",
       "                         addr  e  \n",
       "0      REINDEER CT & DEAD END  1  \n",
       "1  BRIAR PATH & WHITEMARSH LN  1  \n",
       "2                    HAWS AVE  1  \n",
       "3          AIRY ST & SWEDE ST  1  \n",
       "4    CHERRYWOOD CT & DEAD END  1  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importando as libs\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Lendo o dataset\n",
    "df = pd.read_csv('911.csv')\n",
    "\n",
    "# Testando se está tudo certo\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identificando linhas nulas\n",
    "\n",
    "Como já abordada no artigo anterior, onde explico mais a fundo como funciona, vamos utilizar o metodo isnull junto de sum para identificar os dados faltantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lat              0\n",
       "lng              0\n",
       "desc             0\n",
       "zip          39590\n",
       "title            0\n",
       "timeStamp        0\n",
       "twp            115\n",
       "addr             0\n",
       "e                0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Identificando dados faltantes\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## O que sabemos até agora:\n",
    "    \n",
    "Bom até aqui vemos que mais de 39 mil colunas de zip code estão nulas, e também que 115 de twp, que é referente as cidades, também estão vazias\n",
    "\n",
    "Vamos criar um caso que a coluna de cidades é essencial para nossa análise, então linhas que tem este dado faltante devem ser excluídas, então vamos lá limpar as linhas com cidade faltante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limpando dados nulos de uma coluna específica\n",
    "df = df.dropna(subset=['twp'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explicando o método\n",
    "\n",
    "Utilizamos o metodo dropna para fazer as alterações, agora vamos entender seus parâmetros\n",
    "\n",
    "df.dropna(axis=0, how='any', thresh=None, subset=None, inplace=False)\n",
    "\n",
    "- axis: Se for 0 'dropa' as linhas que contem os dados faltantes, caso 1 remove a coluna inteira que tem dados faltantes;\n",
    "- how: Determina se a coluna vai ser removida do DataFrame, se passarmos 'any' como valor do parâmetro se tiver apenas um valor faltante que seja a coluna é removida, se passarmos 'all' precisamos que todos os valores sejam faltantes/nulos para que a coluna seja removida;\n",
    "- thresh: com um inteiro, podemos definir o mínimo de colunas de NaN aceitáveis para começar a dropar, ex: caso tenha thresh = 50, precisamos que a coluna tenha mais 50 de valorers faltantes para o método ser aplicado;\n",
    "- subset: se estamos removendo linhas, podemos inserir um array de colunas onde o metodo será aplicado;\n",
    "- inplace: caso seja True aplica as alterações no dataset de forma automática;\n",
    "\n",
    "Determine if row or column is removed from DataFrame, when we have at least one NA or all NA.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## O que aconteceu?\n",
    "\n",
    "Bom, executamos o metodo dropna no dataset, com o parametro subset para escolher a coluna, assim não mexemos nos dados de zip code\n",
    "\n",
    "Vamos observar as mudanças"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lat              0\n",
       "lng              0\n",
       "desc             0\n",
       "zip          39524\n",
       "title            0\n",
       "timeStamp        0\n",
       "twp              0\n",
       "addr             0\n",
       "e                0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Identificando dados faltantes, após limpar twp\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eliminando todos os dados NaN do dataset:\n",
    "\n",
    "Se na verdade todos os dados NaN podem atrapalhar nossa análise, simplesmente podemos chamar o metodo no dataset\n",
    "\n",
    "Alem disso podemos utilizar o parâmetro inplace = True para não termos que igualar a variável, assim as mudanças já serão salvas automaticamente, veja:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limpando todos os dados nulos do dataset\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lat          0\n",
       "lng          0\n",
       "desc         0\n",
       "zip          0\n",
       "title        0\n",
       "timeStamp    0\n",
       "twp          0\n",
       "addr         0\n",
       "e            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Identificando dados faltantes, após limpar tudo e testando o parâmetro inplace\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusão:\n",
    "\n",
    "Vimos que podemos tanto eliminar linhas com dados faltantes por coluna ou o dataset inteiro\n",
    "\n",
    "Há também outros parâmetros que podem nos ajudar, como o inplace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outro caso\n",
    "\n",
    "Vamos iniciar novamente, importando outro dataset para aplicarmos agora uma tecnica de substituição e não remoção como vimos anteriormente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importando nosso próximo dataset\n",
    "df = pd.read_csv('titanic.csv')\n",
    "\n",
    "# Testando a importação\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      0\n",
       "Survived         0\n",
       "Pclass           0\n",
       "Name             0\n",
       "Sex              0\n",
       "Age            177\n",
       "SibSp            0\n",
       "Parch            0\n",
       "Ticket           0\n",
       "Fare             0\n",
       "Cabin          687\n",
       "Embarked         2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Identificando dados faltantes\n",
    "df.isnull().sum()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
